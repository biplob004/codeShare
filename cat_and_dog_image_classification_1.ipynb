{"cells":[{"metadata":{},"cell_type":"markdown","source":"## 10 Step Project (Image classification Cat vs Dog)\n#### 1. Import libraries\n#### 2. Download data\n#### 3. Data cleaning\n#### 4. Data preprocessing and converting to tensros\n#### 5. Building model\n#### 6. Loss and optimizer functions\n#### 7. Train the model\n#### 8. Test the model\n#### 9. Save the model\n#### 10. Load saved model"},{"metadata":{},"cell_type":"markdown","source":"## Step1: Import all libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\nimport os\nfrom PIL import Image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step2: Download data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"!conda install -y gdown # or use !pip3 install -y gdown if using conda \n!gdown https://drive.google.com/uc?id=1TWjI7ucryVPGMpUMq8cdigYrtKQtc54t # downloading cat and dog images\n!unzip kagglecatsanddogs_3367a.zip ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step3: Clean data and remove non image files"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# cleaning data\n\npath = 'PetImages'\n\nfor folder in os.listdir(path): # Get all folder names --> ['Cat', 'Dog']\n    for img_file in os.listdir(os.path.join(path, folder)): # Loop each folder to get all image files\n        img_file = os.path.join(path, folder, img_file) # creating full path for each image file\n        \n        try:\n            img = Image.open(img_file)\n            if img.mode != 'RGB':\n                os.remove(img_file) # removing gray scale images \n        except:\n            os.remove(img_file) # removing file type None images\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step4: Data preprocessing and convert to tensor format\n"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# pre-process data\n\ntransform = transforms.Compose([\n                                transforms.Resize(255),  # resize img to 255px square image\n                                transforms.CenterCrop(224), # then center crop by 224px\n                                transforms.ToTensor(), # convert into tensor format\n                                transforms.Normalize([0.5], [0.5]) # normalize tensors.\n                               ]) \n\ndataset = datasets.ImageFolder('PetImages', transform=transform)\n\ndataset_len = len(dataset) # get total number of images in all folders.\n\ntrain_len, test_len = dataset_len-6000, 6000 # Keep 6000 images for test_set and others are for training\ntrain_set, test_set = torch.utils.data.random_split(dataset, [train_len, test_len]) # split train and test dataset\nbatch_size = 200\n\n# train and test dataloader\ntrain_set = DataLoader(dataset=train_set, shuffle=True, batch_size=batch_size)\ntest_set = DataLoader(dataset=test_set, shuffle=True, batch_size=batch_size)\n\n# if cuda available then use device as cuda else use cpu\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint('Using device: ',device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step5: Build Model\n"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# CNN model \n\nclass Model(torch.nn.Module):\n  def __init__(self):\n    super(Model, self).__init__()\n    \n    self.pool = nn.MaxPool2d(2,2)\n    self.dropout = nn.Dropout(p=0.2)\n    \n    self.conv1 = nn.Conv2d( in_channels=3,  out_channels=6,  kernel_size=4)\n    self.conv2 = nn.Conv2d( in_channels=6,  out_channels=12, kernel_size=4)\n    self.conv3 = nn.Conv2d( in_channels=12, out_channels=14, kernel_size=4)\n    self.conv4 = nn.Conv2d( in_channels=14, out_channels=16, kernel_size=4)\n    self.conv5 = nn.Conv2d( in_channels=16, out_channels=20, kernel_size=4)\n    \n    self.fc1 = nn.Linear( in_features= 20*4*4, out_features=250 ) \n    self.fc2 = nn.Linear( in_features=250,     out_features=200 )\n    self.fc3 = nn.Linear( in_features=200,     out_features=50  )\n    self.fc4 = nn.Linear( in_features=50,      out_features=10  )\n    self.fc5 = nn.Linear( in_features=10,      out_features=2   )\n  \n  \n  def forward(self, x): # sahpe of x is [batch_size, channel, height, width]\n    x = self.pool(F.relu(self.conv1(x)))\n    x = self.pool(F.relu(self.conv2(x)))\n    x = self.pool(F.relu(self.conv3(x)))\n    x = self.pool(F.relu(self.conv4(x)))\n    x = self.pool(F.relu(self.conv5(x)))\n\n    x = x.reshape(-1, 20*4*4)\n    x = self.dropout(F.relu(self.fc1(x)))\n    x = self.dropout(F.relu(self.fc2(x)))\n    x = self.dropout(F.relu(self.fc3(x)))\n    x = self.dropout(F.relu(self.fc4(x)))\n    x = self.fc5(x)\n    return x\n\n\nnet = Model().to(device)\n\nprint(net)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## step6: Define Loss and optimizer functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# optimizer and loss functions\ncriterion = nn.CrossEntropyLoss() # crossentropy loss for classification problem\noptimizer = optim.Adam(net.parameters(), lr=0.001, weight_decay=1e-5) # lr and weight_decay are hyper parameters\n#optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step7: Train Data"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# train model\n\nnet.train()\n\nfor epoch in range(15):\n  total_correct = 0.0\n  running_loss = 0.0\n  for i, (inputs, labels) in enumerate(train_set):\n    inputs, labels = inputs.to(device), labels.to(device)\n    output = net(inputs)\n    output_idx = torch.argmax(output, dim=1)\n    total_correct += (labels == output_idx).sum().item()\n    optimizer.zero_grad()\n    loss = criterion(output, labels)\n    running_loss += loss.item() * inputs.size(0)\n    loss.backward()\n    optimizer.step()\n    \n  print(f'Epoch: {epoch}  Loss: {running_loss/train_len}   Accuracy:{(total_correct/train_len)*100}%')\n\nprint('Finished training')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step8: Test Data"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# Test our model\n\nwith torch.no_grad(): \n  net.eval()\n  total_loss = 0.0\n  total_correct = 0.0\n  \n  for inputs, labels in test_set:\n    labels = labels.to(device)\n    outputs = net(inputs.to(device))\n    loss = criterion(outputs, labels)\n    total_loss += loss.item() * inputs.size(0)\n    output_idx = torch.argmax(outputs, dim=1)\n    total_correct += sum(labels==output_idx)\n    \n  print(f'Accuracy : {(total_correct/test_len)*100}%  Loss: {total_loss/ test_len}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step9: Save trained model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the model\ntorch.save(net.state_dict(), 'cat_vs_dog.pt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Step10: Load saved model and test it on test data"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"\n# Test from saved .pt model\nwith torch.no_grad():\n  model = Model().to(device)\n  model.load_state_dict(torch.load('cat_vs_dog.pt'))\n  model.eval()\n\n  total_correct = 0.0\n\n  for inputs, labels in test_set:\n    labels = labels.to(device)\n    outputs = model(inputs.to(device))\n    output_idx = torch.argmax(outputs, dim=1)\n    total_correct += sum(labels==output_idx)\n  print(f'Accuracy : {(total_correct/test_len)*100}% ')\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}