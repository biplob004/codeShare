{"cells":[{"metadata":{"_uuid":"dc83c491-711e-4278-b0cc-24896e3e812f","_cell_guid":"5848330f-e52f-49a7-ac18-ab07b0cb8136","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom torchtext.datasets import IMDB\nfrom torchtext.data import Field, LabelField, BucketIterator","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SRC = Field(tokenize = 'spacy', lower = True)\nTRG = LabelField(dtype = torch.int64)\n\ntrain_data, test_data = IMDB.splits(SRC, TRG) # download imdb dataset","execution_count":3,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n/opt/conda/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\naclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]","name":"stderr"},{"output_type":"stream","text":"downloading aclImdb_v1.tar.gz\n","name":"stdout"},{"output_type":"stream","text":"aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:02<00:00, 35.5MB/s]\n/opt/conda/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display lenght of test and traing data\nprint(f\"Number of training examples: {len(train_data.examples)}\")\nprint(f\"Number of testing examples: {len(test_data.examples)}\")","execution_count":4,"outputs":[{"output_type":"stream","text":"Number of training examples: 25000\nNumber of testing examples: 25000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display single example at index 0\nprint(vars(train_data.examples[0]))","execution_count":5,"outputs":[{"output_type":"stream","text":"{'text': ['for', 'a', 'comedy', 'this', 'has', 'a', 'decent', 'and', 'inventive', 'plot', 'and', 'trey', 'parker', 'and', 'matt', 'stone', \"'s\", 'comic', 'timing', 'is', 'perfect', '.', 'there', 'are', 'dozens', 'of', 'funny', 'moments', 'to', 'this', 'fantastic', 'movie', '.', 'i', 'especially', 'like', 'the', 'multitude', 'of', 'colors', 'and', 'the', 'way', 'the', 'clash', 'in', 'the', 'sports', 'arena', 'scenes', '.', 'robert', 'stacks', 'unsolved', 'mysteries', 'spoof', 'is', 'also', 'very', 'amusing', '.'], 'label': 'pos'}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build vocabulary for source and target from training data\n\nSRC.build_vocab(train_data, max_size=10000, min_freq=5, vectors=\"glove.6B.100d\")  # using pretrained word embedding\nTRG.build_vocab(train_data, min_freq = 5)\n\nprint(vars(TRG.vocab))\nprint(f\"Unique tokens in source vocabulary: {len(SRC.vocab)}\")\nprint(f\"Unique tokens in TRG vocabulary: {len(TRG.vocab)}\")","execution_count":6,"outputs":[{"output_type":"stream","text":".vector_cache/glove.6B.zip: 862MB [06:28, 2.22MB/s]                               \n100%|█████████▉| 399999/400000 [00:25<00:00, 15812.95it/s]\n","name":"stderr"},{"output_type":"stream","text":"{'freqs': Counter({'pos': 12500, 'neg': 12500}), 'itos': ['neg', 'pos'], 'unk_index': None, 'stoi': defaultdict(None, {'neg': 0, 'pos': 1}), 'vectors': None}\nUnique tokens in source vocabulary: 10002\nUnique tokens in TRG vocabulary: 2\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nBATCH_SIZE = 100\n\n# train and test iteartor\ntrain_iterator,test_iterator = BucketIterator.splits(\n      (train_data, test_data), \n      batch_size = BATCH_SIZE, \n      device = device\n    )","execution_count":7,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model class\nclass Model(nn.Module):\n  def __init__(self, input_dim, output_dim,emb_dim, hidden_dim, n_layers, dropout):\n    # input_dim <--- vocabulary size\n    # output_dim <--- len ([positive, negative]) == 2 \n    # emb_dim <--- embedding dimension of embedding matrix\n    \n    super(Model, self).__init__()\n    self.n_layers = n_layers\n    self.hidden_dim = hidden_dim\n    \n    self.embedding = nn.Embedding(input_dim, emb_dim)\n    self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout)\n    \n    self.fc1 = nn.Linear(hidden_dim, hidden_dim//2)\n    self.fc2 = nn.Linear(hidden_dim//2, output_dim)\n    \n    self.relu = nn.ReLU()\n    self.dropout = nn.Dropout(dropout)\n\n  def forward(self, src):\n    # shape: [source_len, batch_size]\n    embedded = self.dropout(self.embedding(src)) # sahpe: [src_len, batch_size, embed_dim]\n    output, (hidden, cell) = self.rnn(embedded) \n    # output shape -> [batch, hidden_dim]\n    # hiddden shape -> [n_layers, batch, hidden_dim]\n    # cell shape -> [n_layers, batch, hidden_dim]\n    output = self.fc1(output[-1])\n    output = self.fc2(self.relu(output))\n    return output","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#initializing variables and hyper parameters\nINPUT_DIM = len(SRC.vocab)\nOUTPUT_DIM = len(TRG.vocab)\nENC_EMB_DIM = 100\nDEC_EMB_DIM = 100\nHID_DIM = 512\nN_LAYERS = 2\nENC_DROPOUT = 0.5\nDEC_DROPOUT = 0.5\n\n# initializing our model\nmodel = Model(INPUT_DIM, OUTPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT).to(device)\n\n# loading pretrained word embedding\nmodel.embedding.weight.data.copy_(SRC.vocab.vectors) ","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n        ...,\n        [ 0.0402, -0.4874,  0.7354,  ...,  0.1813, -0.4743, -0.4879],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [-0.5194, -0.6982,  0.2841,  ...,  0.3718, -0.4543, -0.4990]],\n       device='cuda:0')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=3e-3)\n\n# defining learnig rate scheduler (optional)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n\ncriterion = nn.CrossEntropyLoss()\n\n\n# Model training function\ndef train(model, iterator, optimizer=optimizer, criterion=criterion, clip=1):\n    model.train()\n    epoch_loss = 0\n    total_correct = 0\n    total_count = 0\n    \n    for i, batch in enumerate(iterator):\n        src = batch.text.to(device)\n        trg = batch.label.to(device)\n        optimizer.zero_grad()\n        output = model(src)\n        \n        total_correct += torch.sum(torch.eq(output.argmax(1), trg))\n        total_count+=len(trg)\n        \n        loss = criterion(output, trg)\n        \n        loss.backward() \n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        epoch_loss += loss.item()\n        \n    print(f'correct: {total_correct}/{total_count}')\n    mean_loss = epoch_loss / len(iterator)\n    scheduler.step(mean_loss)\n    return mean_loss # mean loss","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loop and train our model\ntotal_epoch = 120\nfor epoch in range(total_epoch):\n  result = train(model=model, iterator=train_iterator)\n  print(f'Epoch {epoch} -->', result)","execution_count":null,"outputs":[{"output_type":"stream","text":"correct: 12562/25000\nEpoch 0 --> 0.6955907859802246\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function to experiment movie review sentences\nimport spacy\n\n!python -m spacy download en # dwonload english from spacy\n\nsp = spacy.load('en')\n\n\ndef predict(sentence):\n\n  if type(sentence) == str:\n    tokanized_sentence = [word.text for word in sp.tokenizer(sentence)]\n  else:\n    tokanized_sentence = sentence\n\n\n  input_data = [SRC.vocab.stoi[word.lower()] for word in tokanized_sentence]\n  input_data = torch.tensor(input_data, dtype=torch.int64).unsqueeze(1).to(device)\n\n\n  model.eval()\n  output = model(input_data)\n  # print(output)\n  predict = output.argmax(1)\n  predict = predict.squeeze(0)\n  print(output)\n\n  if predict>0:\n    return \"---->> Positive Review\"\n  else:\n    return '---->> Negative Review'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict('i have enjoyed this movie') # predict funciton will predict if this is positive or negative review.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}